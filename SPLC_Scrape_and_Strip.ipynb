{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in raw scraped files from directory\n",
    "### 2. Strip HTML\n",
    "### 3. Extract entities (using spacy)\n",
    "### 3. Remove special characters / unicode\n",
    "#### Created by Jackie Weiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re, string\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy is used for Part of Speech tagging and Named Entity Recognition\n",
    "# spacy is a non-standard python library which can be installed using 'pip install spacy' from the command line\n",
    "# language models can be downloaded by running 'python -m spacy download <language>' from the command line\n",
    "import spacy\n",
    "language = 'en'\n",
    "nlp_model  = spacy.load('en')\n",
    "    \n",
    "def get_multilingual_entities(text):\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    labels = [{ent.text:ent.label_} for ent in doc.ents]\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_docs = './'\n",
    "output_clean = 'clean_scraped_text/clean_scraped_text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stripTags(text):\n",
    "    scripts = re.compile(r'<script.*?/script>')\n",
    "    css = re.compile(r'<style.*?/style>')\n",
    "    tags = re.compile(r'<.*?>')\n",
    "\n",
    "    text = scripts.sub('', text)\n",
    "    text = css.sub('', text)\n",
    "    text = tags.sub('', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def punctuation_remove(text):\n",
    "    \"\"\"\n",
    "    Mutates and returns text where all punctuation are replaced\n",
    "    \"\"\"\n",
    "    chars = re.escape(string.punctuation)\n",
    "    return re.sub(r'['+chars+']', ' ',text)\n",
    "\n",
    "def doublespace_remove(text):\n",
    "    return re.sub(' +',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "webfiles = [webfile for webfile in os.listdir(path_to_docs) if '.' in webfile]\n",
    "htmlfiles = [{webfile:htmlfile} for htmlfile in os.listdir(path_to_docs + webfile) if htmlfile.endswith('.html') for webfile in webfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "characters_to_replace = ['\\u']\n",
    "htmldict = {}\n",
    "for webfile in webfiles[0:10]:\n",
    "    if not webfile in ['.gitignore','.DS_Store', '.git', '.ipynb_checkpoints','RawUrls.txt','README.md','SPLC_Strip_HTML.ipynb']:\n",
    "        htmlfiles = [htmlfile for htmlfile in os.listdir(path_to_docs + webfile) if htmlfile.endswith('.html')]\n",
    "        for htmlfile in htmlfiles:\n",
    "            htmldict[webfile] = {}\n",
    "            htmldict[webfile][htmlfile] = {}\n",
    "            with open(path_to_docs + webfile + '/' + htmlfile, \"r\") as myfile:\n",
    "                result = myfile.read()\n",
    "            htmldict[webfile][htmlfile]['text'] = text_from_html(result)\n",
    "            entities = get_multilingual_entities(htmldict[webfile][htmlfile]['text'])\n",
    "            for char in characters_to_replace:\n",
    "                htmldict[webfile][htmlfile]['text'] = htmldict[webfile][htmlfile]['text'].encode('ascii','replace').lower().replace(char,\" \")\n",
    "            htmldict[webfile][htmlfile]['text'] = punctuation_remove(htmldict[webfile][htmlfile]['text'])\n",
    "            htmldict[webfile][htmlfile]['text'] = doublespace_remove(htmldict[webfile][htmlfile]['text'])\n",
    "            htmldict[webfile][htmlfile]['entities'] = entities\n",
    "            with open(output_clean, \"a\") as myfile:\n",
    "                myfile.write(str(htmldict[webfile][htmlfile]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['americanfreepress.net',\n",
       " 'active-democracy.com',\n",
       " 'addr.ws',\n",
       " 'americanvikings.us',\n",
       " 'americanvikings.com']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmldict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'                       ': u'GPE'},\n",
       " {u'Terms Of Service': u'ORG'},\n",
       " {u' ': u'NORP'},\n",
       " {u'ABOUT  HELP  PRIVACY': u'QUANTITY'},\n",
       " {u'POLICY       Facebook': u'ORG'},\n",
       " {u'Twitter': u'GPE'},\n",
       " {u'Youtube       ': u'PERSON'},\n",
       " {u' ': u'NORP'},\n",
       " {u'Multimedia   Radio': u'ORG'},\n",
       " {u'Audio': u'PERSON'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmldict['americanfreepress.net']['index.html']['entities'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' terms of service about help privacy policy facebook twitter youtube search for home multimedia radio video audio the andrew carrington hitchcock afp show archives support store subscribe about login news ticker march 30 2017 american free press is under attack national news november 11 2017 trump will release jfk documents audio november 10 2017 that bloodbath in the old dominion politics november 10 2017 gop tax plan increases the most insidious tax freedom november 10 2017 globalists seek to scuttle brexit world november 7 2017 democrats behind fake news dossier featured audio trump will release jfk documents politics that bloodbath in the old dominion freedom gop tax plan increases the most insidious tax world globalists seek to scuttle brexit featured democrats behind fake news dossier featured cleaning house conspiracy buzz rhode island tackles geoengineering audio homelessness infectious diseases combine to create health disaster audio top tier treason and the uss liberty national news media watchdog group catches shocking nyt admission on tape audio interview https youtu be aphayocfxeo national news featured democrats behind fake news dossier november 7 2017 0 the hillary clinton campaign and the dnc have been tied to the bogus report on trump s deep compromising ties to russia which even former fbi director james comey called salacious and unverified that was released before democrats behind fake news dossier november 7 2017 0 cleaning house november 2 2017 2 rhode island tackles geoengineering october 27 2017 3 homelessness infectious diseases combine to create health disaster october 25 2017 3 world news world globalists seek to scuttle brexit november 10 2017 0 the new world order elite just won t let the british put britain first by mark anderson the british brexit vote cast june 23 2016 provided a clear indication of the populist revolt that s been simmering for globalists seek to scuttle brexit november 10 2017 0 two lost thorn books back in print oct'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmldict['americanfreepress.net']['index.html']['text'][0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
